#!/usr/bin/env python3

import os
import sys
import json
import asyncio
from typing import AsyncGenerator, Dict, List, Optional, Union
from pathlib import Path
from dotenv import load_dotenv

# Load environment variables from .env file
env_path = Path(__file__).resolve().parent.parent / '.env'
load_dotenv(env_path)

# Verify API key is set
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY not found in environment variables. Please set it in .env file.")

from openai import OpenAI
from agents import Agent, Runner, gen_trace_id, trace, ModelSettings
from agents.mcp import MCPServerStdio

# Default model configuration
DEFAULT_MODEL = "gpt-4o"  # or gpt-4 or gpt-3.5-turbo

async def run_agent(
    prompt: str,
    mcp_proxy_addr: str = "mcp-proxy-agent-1",
    trace_file: Optional[str] = "agent_trace.jsonl",
    model: str = DEFAULT_MODEL
) -> str:
    """
    Run the OpenAI agent with the given prompt in non-streaming mode.
    
    Args:
        prompt: The user prompt to process
        mcp_proxy_addr: The MCP proxy address
        trace_file: File to save traces to, None to disable tracing
        model: The OpenAI model to use (default: gpt-4o)
    
    Returns:
        The complete response as a string
    """
    # Setup OpenAI client
    client = OpenAI()
    
    # Generate trace ID for this run
    trace_id = gen_trace_id()
    
    # Connect to MCP server using stdio mode
    async with MCPServerStdio(
        name="MCP Proxy Server",
        params={
            "command": "/Users/frankhe/.local/bin/mcp-proxy",
            "args": ["https://sequencer-v2.heurist.xyz/mcp/sse"],
        }
    ) as mcp_server:
        # Create the agent with model settings
        model_settings = ModelSettings(
            temperature=0.1,  # Lower temperature for more focused responses
            max_tokens=2000,  # Reasonable length for responses
        )
        
        agent = Agent(
            name="Assistant",
            instructions="You are a helpful assistant that uses tools to answer user questions.",
            mcp_servers=[mcp_server],
            model=model,
            model_settings=model_settings
        )
        
        # Run with tracing
        with trace(workflow_name="MCP Agent", trace_id=trace_id):
            print(f"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\n")
            
            # Run the agent
            result = await Runner.run(
                starting_agent=agent,
                input=prompt
            )
            
            return result.final_output

async def main():
    """Main entry point for the CLI application."""
    print("OpenAI Agent with MCP Server (Non-Streaming Mode)")
    print("Type 'exit' to quit\n")
    
    while True:
        try:
            prompt = input("üë§ You: ")
            if prompt.lower() in ("exit", "quit"):
                break
            
            print("ü§ñ Assistant: ", end="")
            
            # Show a loading indicator
            loading_task = asyncio.create_task(show_loading())
            
            # Run agent without streaming
            response = await run_agent(prompt)
            
            # Cancel the loading indicator
            loading_task.cancel()
            try:
                await loading_task
            except asyncio.CancelledError:
                pass
            
            # Clear the loading indicator and print the response
            print("\r" + " " * 10 + "\r" + response)
            
        except KeyboardInterrupt:
            print("\nExiting...")
            break
        except Exception as e:
            print(f"\nError: {e}")

async def show_loading():
    """Display a simple loading animation."""
    symbols = ["‚†ã", "‚†ô", "‚†π", "‚†∏", "‚†º", "‚†¥", "‚†¶", "‚†ß", "‚†á", "‚†è"]
    i = 0
    try:
        while True:
            print(f"\r{symbols[i % len(symbols)]}", end="", flush=True)
            i += 1
            await asyncio.sleep(0.1)
    except asyncio.CancelledError:
        print("\r", end="", flush=True)
        raise

if __name__ == "__main__":
    asyncio.run(main()) 